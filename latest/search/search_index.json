{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kiara plugin: tabular \u00b6 This package contains a set of commonly used/useful modules, pipelines, types and metadata schemas for Kiara . Description \u00b6 kiara data-types and modules for working with tables and databases. Package content \u00b6 data_types \u00b6 array : An array, in most cases used as a column within a table. table : Tabular data (table, spreadsheet, data_frame, what have you). module_types \u00b6 table.save_to.disk.as.feather : -- n/a -- table.import : -- n/a -- table.load_from.disk : -- n/a -- Links \u00b6 Documentation: https://DHARPA-Project.github.io/kiara_plugin.tabular Code: https://github.com/DHARPA-Project/kiara_plugin.tabular","title":"Home"},{"location":"#kiara-plugin-tabular","text":"This package contains a set of commonly used/useful modules, pipelines, types and metadata schemas for Kiara .","title":"kiara plugin: tabular"},{"location":"#description","text":"kiara data-types and modules for working with tables and databases.","title":"Description"},{"location":"#package-content","text":"","title":"Package content"},{"location":"#data_types","text":"array : An array, in most cases used as a column within a table. table : Tabular data (table, spreadsheet, data_frame, what have you).","title":"data_types"},{"location":"#module_types","text":"table.save_to.disk.as.feather : -- n/a -- table.import : -- n/a -- table.load_from.disk : -- n/a --","title":"module_types"},{"location":"#links","text":"Documentation: https://DHARPA-Project.github.io/kiara_plugin.tabular Code: https://github.com/DHARPA-Project/kiara_plugin.tabular","title":"Links"},{"location":"SUMMARY/","text":"Home Usage Package contents API reference","title":"SUMMARY"},{"location":"usage/","text":"Usage \u00b6 TO BE DONE","title":"Usage"},{"location":"usage/#usage","text":"TO BE DONE","title":"Usage"},{"location":"info/SUMMARY/","text":"data_types module_types","title":"SUMMARY"},{"location":"info/data_types/","text":"array \u00b6 Documentation An array, in most cases used as a column within a table. Internally, this type uses the Apache Arrow Array to store the data in memory (and on disk). Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kiara_plugin\u2026 documentation : https://DHARPA-Project.github.io/kiara_plugin.\u2026 Python class class_name ArrayType module_name kiara_plugin.tabular.data_types full_name kiara_plugin.tabular.data_types.ArrayType Config class class_name DataTypeConfig module_name kiara.data_types full_name kiara.data_types.DataTypeConfig Value class class_name KiaraArray module_name kiara_plugin.tabular.data_types full_name kiara_plugin.tabular.data_types.KiaraArray table \u00b6 Documentation Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the Apache Arrow Table class. Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kiara_plugin\u2026 documentation : https://DHARPA-Project.github.io/kiara_plugin.\u2026 Python class class_name TableType module_name kiara_plugin.tabular.data_types full_name kiara_plugin.tabular.data_types.TableType Config class class_name DataTypeConfig module_name kiara.data_types full_name kiara.data_types.DataTypeConfig Value class class_name Table module_name pyarrow.lib full_name pyarrow.lib.Table","title":"data_types"},{"location":"info/data_types/#kiara_info.data_types.array","text":"Documentation An array, in most cases used as a column within a table. Internally, this type uses the Apache Arrow Array to store the data in memory (and on disk). Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kiara_plugin\u2026 documentation : https://DHARPA-Project.github.io/kiara_plugin.\u2026 Python class class_name ArrayType module_name kiara_plugin.tabular.data_types full_name kiara_plugin.tabular.data_types.ArrayType Config class class_name DataTypeConfig module_name kiara.data_types full_name kiara.data_types.DataTypeConfig Value class class_name KiaraArray module_name kiara_plugin.tabular.data_types full_name kiara_plugin.tabular.data_types.KiaraArray","title":"array"},{"location":"info/data_types/#kiara_info.data_types.table","text":"Documentation Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the Apache Arrow Table class. Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kiara_plugin\u2026 documentation : https://DHARPA-Project.github.io/kiara_plugin.\u2026 Python class class_name TableType module_name kiara_plugin.tabular.data_types full_name kiara_plugin.tabular.data_types.TableType Config class class_name DataTypeConfig module_name kiara.data_types full_name kiara.data_types.DataTypeConfig Value class class_name Table module_name pyarrow.lib full_name pyarrow.lib.Table","title":"table"},{"location":"info/module_types/","text":"table.save_to.disk.as.feather \u00b6 Documentation -- n/a -- Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kia\u2026 documentation : https://DHARPA-Project.github.io/kiar\u2026 Module config schema Field Type Descript\u2026 Required Default \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 constants object Value no constants for this module. defaults object Value no defaults for this module. source_t\u2026 string The value yes type of the source. source_t\u2026 object The value no type config (if applicab\u2026 Python class class_name SaveTableToDiskModule module_name kiara_plugin.tabular.tabular full_name kiara_plugin.tabular.tabular.SaveTab\u2026 Processing source code \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def process (self, inputs: ValueSet, outputs: Value\u2026 source_type = self . get_config_value( \"source_ty\u2026 value = inputs . get_value_obj(source_type) func_name = f\"data_type__{ self . get_config_valu\u2026 func = getattr(self, func_name) result: LoadConfig bytes_structure: Optional[BytesStructure] result, bytes_structure = func(value = value, pe\u2026 outputs . set_values(load_config = result, bytes_s\u2026 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 table.import \u00b6 Documentation -- n/a -- Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kia\u2026 documentation : https://DHARPA-Project.github.io/kiar\u2026 Module config schema Field Type Descript\u2026 Required Default \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 constan\u2026 object Value no constants for this module. defaults object Value no defaults for this module. ignore_\u2026 boolean Whether no false to ignore convert errors and omit the failed items. source_\u2026 string The yes source profile name. source_\u2026 string The yes source data type. Python class class_name CreateTableModule module_name kiara_plugin.tabular.tabular full_name kiara_plugin.tabular.tabular.CreateT\u2026 Processing source code \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def process (self, inputs: ValueSet, outputs: Value\u2026 source_type = self . get_config_value( \"source_ty\u2026 source_profile_name = self . get_config_value( \"s\u2026 func_name = f\"create_from__{ source_profile_nam\u2026 func = getattr(self, func_name) source_value = inputs . get_value_obj(source_typ\u2026 result = func(source_value = source_value) outputs . set_value( \"table\" , KiaraTable . create_t\u2026 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 table.load_from.disk \u00b6 Documentation -- n/a -- Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kia\u2026 documentation : https://DHARPA-Project.github.io/kiar\u2026 Module config schema Field Type Descript\u2026 Required Default \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 constants object Value no constants for this module. defaults object Value no defaults for this module. only_col\u2026 string Whether no to only load a single column instead of the whole table. Python class class_name LoadTableFromDiskModule module_name kiara_plugin.tabular.tabular full_name kiara_plugin.tabular.tabular.LoadTab\u2026 Processing source code \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def process (self, inputs: ValueSet, outputs: Value\u2026 import pyarrow as pa bytes_structure: BytesStructure = inputs . get_v\u2026 if not self . get_config_value( \"only_column\" ): columns = {} for column_name, chunks in bytes_structure \u2026 assert len(chunks) == 1 with pa . memory_map(chunks[ 0 ], \"r\" ) as \u2026 loaded_arrays: pa . Table = pa . ipc . o\u2026 column = loaded_arrays . column(colu\u2026 columns[column_name] = column arrow_table = pa . table(columns) table = KiaraTable . create_table(arrow_tabl\u2026 outputs . set_value( \"table\" , table) else : chunks = bytes_structure . chunk_map[ \"array.\u2026 assert len(chunks) == 1 with pa . memory_map(chunks[ 0 ], \"r\" ) as colu\u2026 loaded_arrays = pa . ipc . open_file(colum\u2026 column = loaded_arrays . column( \"array\" ) array = KiaraArray . create_array(column) outputs . set_value( \"array\" , array) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"module_types"},{"location":"info/module_types/#kiara_info.module_types.table.save_to.disk.as.feather","text":"Documentation -- n/a -- Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kia\u2026 documentation : https://DHARPA-Project.github.io/kiar\u2026 Module config schema Field Type Descript\u2026 Required Default \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 constants object Value no constants for this module. defaults object Value no defaults for this module. source_t\u2026 string The value yes type of the source. source_t\u2026 object The value no type config (if applicab\u2026 Python class class_name SaveTableToDiskModule module_name kiara_plugin.tabular.tabular full_name kiara_plugin.tabular.tabular.SaveTab\u2026 Processing source code \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def process (self, inputs: ValueSet, outputs: Value\u2026 source_type = self . get_config_value( \"source_ty\u2026 value = inputs . get_value_obj(source_type) func_name = f\"data_type__{ self . get_config_valu\u2026 func = getattr(self, func_name) result: LoadConfig bytes_structure: Optional[BytesStructure] result, bytes_structure = func(value = value, pe\u2026 outputs . set_values(load_config = result, bytes_s\u2026 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"table.save_to.disk.as.feather"},{"location":"info/module_types/#kiara_info.module_types.table.import","text":"Documentation -- n/a -- Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kia\u2026 documentation : https://DHARPA-Project.github.io/kiar\u2026 Module config schema Field Type Descript\u2026 Required Default \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 constan\u2026 object Value no constants for this module. defaults object Value no defaults for this module. ignore_\u2026 boolean Whether no false to ignore convert errors and omit the failed items. source_\u2026 string The yes source profile name. source_\u2026 string The yes source data type. Python class class_name CreateTableModule module_name kiara_plugin.tabular.tabular full_name kiara_plugin.tabular.tabular.CreateT\u2026 Processing source code \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def process (self, inputs: ValueSet, outputs: Value\u2026 source_type = self . get_config_value( \"source_ty\u2026 source_profile_name = self . get_config_value( \"s\u2026 func_name = f\"create_from__{ source_profile_nam\u2026 func = getattr(self, func_name) source_value = inputs . get_value_obj(source_typ\u2026 result = func(source_value = source_value) outputs . set_value( \"table\" , KiaraTable . create_t\u2026 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"table.import"},{"location":"info/module_types/#kiara_info.module_types.table.load_from.disk","text":"Documentation -- n/a -- Author(s) Markus Binsteiner markus@frkl.io Context Tags tabular Labels package : kiara_plugin.tabular References source_repo : https://github.com/DHARPA-Project/kia\u2026 documentation : https://DHARPA-Project.github.io/kiar\u2026 Module config schema Field Type Descript\u2026 Required Default \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 constants object Value no constants for this module. defaults object Value no defaults for this module. only_col\u2026 string Whether no to only load a single column instead of the whole table. Python class class_name LoadTableFromDiskModule module_name kiara_plugin.tabular.tabular full_name kiara_plugin.tabular.tabular.LoadTab\u2026 Processing source code \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 def process (self, inputs: ValueSet, outputs: Value\u2026 import pyarrow as pa bytes_structure: BytesStructure = inputs . get_v\u2026 if not self . get_config_value( \"only_column\" ): columns = {} for column_name, chunks in bytes_structure \u2026 assert len(chunks) == 1 with pa . memory_map(chunks[ 0 ], \"r\" ) as \u2026 loaded_arrays: pa . Table = pa . ipc . o\u2026 column = loaded_arrays . column(colu\u2026 columns[column_name] = column arrow_table = pa . table(columns) table = KiaraTable . create_table(arrow_tabl\u2026 outputs . set_value( \"table\" , table) else : chunks = bytes_structure . chunk_map[ \"array.\u2026 assert len(chunks) == 1 with pa . memory_map(chunks[ 0 ], \"r\" ) as colu\u2026 loaded_arrays = pa . ipc . open_file(colum\u2026 column = loaded_arrays . column( \"array\" ) array = KiaraArray . create_array(column) outputs . set_value( \"array\" , array) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"table.load_from.disk"},{"location":"reference/SUMMARY/","text":"kiara_plugin tabular data_types models pipelines tabular","title":"SUMMARY"},{"location":"reference/kiara_plugin/tabular/__init__/","text":"Top-level package for kiara_plugin.tabular. KIARA_METADATA \u00b6 find_data_types : Union [ Type , Tuple , Callable ] \u00b6 find_modules : Union [ Type , Tuple , Callable ] \u00b6 find_pipelines : Union [ Type , Tuple , Callable ] \u00b6 find_value_metadata : Union [ Type , Tuple , Callable ] \u00b6 get_version () \u00b6 Source code in tabular/__init__.py def get_version (): from pkg_resources import DistributionNotFound , get_distribution try : # Change here if project is renamed and does not equal the package name dist_name = __name__ __version__ = get_distribution ( dist_name ) . version except DistributionNotFound : try : version_file = os . path . join ( os . path . dirname ( __file__ ), \"version.txt\" ) if os . path . exists ( version_file ): with open ( version_file , encoding = \"utf-8\" ) as vf : __version__ = vf . read () else : __version__ = \"unknown\" except ( Exception ): pass if __version__ is None : __version__ = \"unknown\" return __version__ Modules \u00b6 data_types \u00b6 This module contains the value type classes that are used in the kiara_plugin.tabular package. Classes \u00b6 ArrayType ( AnyType ) \u00b6 An array, in most cases used as a column within a table. Internally, this type uses the Apache Arrow Array to store the data in memory (and on disk). Source code in tabular/data_types.py class ArrayType ( AnyType [ KiaraArray , DataTypeConfig ]): \"\"\"An array, in most cases used as a column within a table. Internally, this type uses the [Apache Arrow](https://arrow.apache.org) [Array](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array) to store the data in memory (and on disk). \"\"\" _data_type_name = \"array\" @classmethod def python_class ( cls ) -> Type : return KiaraArray def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) def _validate ( cls , value : Any ) -> None : if not isinstance ( value , ( pa . Array , pa . ChunkedArray )): raise Exception ( f \"Invalid type ' { type ( value ) . __name__ } ', must be an Apache Arrow Array type.\" ) def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result Methods \u00b6 calculate_hash ( self , data ) \u00b6 Calculate the hash of the value. Source code in tabular/data_types.py def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) calculate_size ( self , data ) \u00b6 Source code in tabular/data_types.py def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) parse_python_obj ( self , data ) \u00b6 Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraArray 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) python_class () classmethod \u00b6 Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return KiaraArray render_as_terminal_renderable ( self , value , render_config ) \u00b6 Source code in tabular/data_types.py def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result KiaraArray ( KiaraModel ) pydantic-model \u00b6 Source code in tabular/data_types.py class KiaraArray ( KiaraModel ): # @classmethod # def create_in_temp_dir(cls, ): # # temp_f = tempfile.mkdtemp() # file_path = os.path.join(temp_f, \"array.feather\") # # def cleanup(): # shutil.rmtree(file_path, ignore_errors=True) # # atexit.register(cleanup) # # array_obj = cls(feather_path=file_path) # return array_obj @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _array_obj : pa . Array = PrivateAttr () def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return ARRAY_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_array ( self ) -> pa . Array : if self . _array_obj is not None : return self . _array_obj if not self . data_path : raise Exception ( \"Can't retrieve array data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () if len ( table . columns ) != 1 : raise Exception ( f \"Invalid serialized array data, only a single-column Table is allowed. This value is a table with { len ( table . columns ) } columns.\" ) self . _array_obj = table . column [ 0 ] return self . _array_obj def to_pylist ( self ): return self . arrow_array . to_pylist () def to_pandas ( self ): return self . arrow_array . to_pandas () Attributes \u00b6 arrow_array : Array property readonly \u00b6 data_path : str pydantic-field \u00b6 The path to the (feather) file backing this array. create_array ( data ) classmethod \u00b6 Source code in tabular/data_types.py @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj to_pandas ( self ) \u00b6 Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_array . to_pandas () to_pylist ( self ) \u00b6 Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_array . to_pylist () KiaraTable ( KiaraModel ) pydantic-model \u00b6 Source code in tabular/data_types.py class KiaraTable ( KiaraModel ): @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _table_obj : pa . Table = PrivateAttr ( default = None ) def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return TABLE_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_table ( self ) -> pa . Table : if self . _table_obj is not None : return self . _table_obj if not self . data_path : raise Exception ( \"Can't retrieve table data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () self . _table_obj = table return self . _table_obj @property def column_names ( self ) -> Iterable [ str ]: return self . arrow_table . column_names @property def num_rows ( self ) -> int : return self . arrow_table . num_rows def to_pydict ( self ): return self . arrow_table . to_pydict () def to_pylist ( self ): return self . arrow_table . to_pylist () def to_pandas ( self ): return self . arrow_table . to_pandas () Attributes \u00b6 arrow_table : Table property readonly \u00b6 column_names : Iterable [ str ] property readonly \u00b6 data_path : str pydantic-field \u00b6 The path to the (feather) file backing this array. num_rows : int property readonly \u00b6 create_table ( data ) classmethod \u00b6 Source code in tabular/data_types.py @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj to_pandas ( self ) \u00b6 Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_table . to_pandas () to_pydict ( self ) \u00b6 Source code in tabular/data_types.py def to_pydict ( self ): return self . arrow_table . to_pydict () to_pylist ( self ) \u00b6 Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_table . to_pylist () TableType ( AnyType ) \u00b6 Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the Apache Arrow Table class. Source code in tabular/data_types.py class TableType ( AnyType ): \"\"\"Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the [Apache Arrow](https://arrow.apache.org) [``Table``](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html) class. \"\"\" _data_type_name = \"table\" @classmethod def python_class ( cls ) -> Type : return pa . Table def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) def _validate ( cls , value : Any ) -> None : pass if not isinstance ( value , KiaraTable ): raise Exception ( f \"invalid type ' { type ( value ) . __name__ } ', must be 'KiaraTable'.\" ) def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result Methods \u00b6 parse_python_obj ( self , data ) \u00b6 Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraTable 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) python_class () classmethod \u00b6 Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return pa . Table render_as__terminal_renderable ( self , value , render_config ) \u00b6 Source code in tabular/data_types.py def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result models \u00b6 This module contains the metadata (and other) models that are used in the kiara_plugin.tabular package. Those models are convenience wrappers that make it easier for kiara to find, create, manage and version metadata -- but also other type of models -- that is attached to data, as well as kiara modules. Metadata models must be a sub-class of kiara.metadata.MetadataModel . Other models usually sub-class a pydantic BaseModel or implement custom base classes. pipelines special \u00b6 Default (empty) module that is used as a base path for pipelines contained in this package. tabular \u00b6 Classes \u00b6 CreateTableModule ( KiaraModule ) \u00b6 Source code in tabular/tabular.py class CreateTableModule ( KiaraModule ): _module_type_name = \"table.import\" _config_cls = CreateTableModuleCOnfig def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result )) def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data Classes \u00b6 _config_cls ( KiaraModuleConfig ) private pydantic-model \u00b6 Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , ) Attributes \u00b6 ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type. Methods \u00b6 create_from__csv__file ( self , source_value ) \u00b6 Source code in tabular/tabular.py def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data create_inputs_schema ( self ) \u00b6 Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs create_outputs_schema ( self ) \u00b6 Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs process ( self , inputs , outputs ) \u00b6 Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result )) CreateTableModuleCOnfig ( KiaraModuleConfig ) pydantic-model \u00b6 Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , ) Attributes \u00b6 ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type. LoadTableConfig ( KiaraModuleConfig ) pydantic-model \u00b6 Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , ) Attributes \u00b6 only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table. LoadTableFromDiskModule ( KiaraModule ) \u00b6 Source code in tabular/tabular.py class LoadTableFromDiskModule ( KiaraModule ): _module_type_name = \"table.load_from.disk\" _config_cls = LoadTableConfig def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array ) Classes \u00b6 _config_cls ( KiaraModuleConfig ) private pydantic-model \u00b6 Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , ) Attributes \u00b6 only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table. Methods \u00b6 create_inputs_schema ( self ) \u00b6 Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs create_outputs_schema ( self ) \u00b6 Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} process ( self , inputs , outputs ) \u00b6 Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array ) SaveTableToDiskModule ( PersistValueModule ) \u00b6 Source code in tabular/tabular.py class SaveTableToDiskModule ( PersistValueModule ): _module_type_name = \"table.save_to.disk.as.feather\" def get_persistence_target_name ( self ) -> str : return \"disk\" def get_persistence_format_name ( self ) -> str : return \"arrays\" def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def _store_array ( self , array_obj : \"pa.Array\" , file_name : str , column_name : \"str\" = \"array\" ): import pyarrow as pa schema = pa . schema ([ pa . field ( column_name , array_obj . type )]) # TODO: support non-single chunk columns with pa . OSFile ( file_name , \"wb\" ) as sink : with pa . ipc . new_file ( sink , schema = schema ) as writer : batch = pa . record_batch ( array_obj . chunks , schema = schema ) writer . write ( batch ) Methods \u00b6 data_type__array ( self , value , persistence_config ) \u00b6 Source code in tabular/tabular.py def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure data_type__table ( self , value , persistence_config ) \u00b6 Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. Source code in tabular/tabular.py def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure get_persistence_format_name ( self ) \u00b6 Source code in tabular/tabular.py def get_persistence_format_name ( self ) -> str : return \"arrays\" get_persistence_target_name ( self ) \u00b6 Source code in tabular/tabular.py def get_persistence_target_name ( self ) -> str : return \"disk\"","title":"tabular"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.KIARA_METADATA","text":"","title":"KIARA_METADATA"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.find_data_types","text":"","title":"find_data_types"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.find_modules","text":"","title":"find_modules"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.find_pipelines","text":"","title":"find_pipelines"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.find_value_metadata","text":"","title":"find_value_metadata"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.get_version","text":"Source code in tabular/__init__.py def get_version (): from pkg_resources import DistributionNotFound , get_distribution try : # Change here if project is renamed and does not equal the package name dist_name = __name__ __version__ = get_distribution ( dist_name ) . version except DistributionNotFound : try : version_file = os . path . join ( os . path . dirname ( __file__ ), \"version.txt\" ) if os . path . exists ( version_file ): with open ( version_file , encoding = \"utf-8\" ) as vf : __version__ = vf . read () else : __version__ = \"unknown\" except ( Exception ): pass if __version__ is None : __version__ = \"unknown\" return __version__","title":"get_version()"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular-modules","text":"","title":"Modules"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types","text":"This module contains the value type classes that are used in the kiara_plugin.tabular package.","title":"data_types"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types-classes","text":"","title":"Classes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.ArrayType","text":"An array, in most cases used as a column within a table. Internally, this type uses the Apache Arrow Array to store the data in memory (and on disk). Source code in tabular/data_types.py class ArrayType ( AnyType [ KiaraArray , DataTypeConfig ]): \"\"\"An array, in most cases used as a column within a table. Internally, this type uses the [Apache Arrow](https://arrow.apache.org) [Array](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array) to store the data in memory (and on disk). \"\"\" _data_type_name = \"array\" @classmethod def python_class ( cls ) -> Type : return KiaraArray def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) def _validate ( cls , value : Any ) -> None : if not isinstance ( value , ( pa . Array , pa . ChunkedArray )): raise Exception ( f \"Invalid type ' { type ( value ) . __name__ } ', must be an Apache Arrow Array type.\" ) def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result","title":"ArrayType"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.ArrayType-methods","text":"calculate_hash ( self , data ) \u00b6 Calculate the hash of the value. Source code in tabular/data_types.py def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) calculate_size ( self , data ) \u00b6 Source code in tabular/data_types.py def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) parse_python_obj ( self , data ) \u00b6 Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraArray 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) python_class () classmethod \u00b6 Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return KiaraArray render_as_terminal_renderable ( self , value , render_config ) \u00b6 Source code in tabular/data_types.py def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result","title":"Methods"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.KiaraArray","text":"Source code in tabular/data_types.py class KiaraArray ( KiaraModel ): # @classmethod # def create_in_temp_dir(cls, ): # # temp_f = tempfile.mkdtemp() # file_path = os.path.join(temp_f, \"array.feather\") # # def cleanup(): # shutil.rmtree(file_path, ignore_errors=True) # # atexit.register(cleanup) # # array_obj = cls(feather_path=file_path) # return array_obj @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _array_obj : pa . Array = PrivateAttr () def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return ARRAY_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_array ( self ) -> pa . Array : if self . _array_obj is not None : return self . _array_obj if not self . data_path : raise Exception ( \"Can't retrieve array data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () if len ( table . columns ) != 1 : raise Exception ( f \"Invalid serialized array data, only a single-column Table is allowed. This value is a table with { len ( table . columns ) } columns.\" ) self . _array_obj = table . column [ 0 ] return self . _array_obj def to_pylist ( self ): return self . arrow_array . to_pylist () def to_pandas ( self ): return self . arrow_array . to_pandas ()","title":"KiaraArray"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.KiaraArray-attributes","text":"arrow_array : Array property readonly \u00b6 data_path : str pydantic-field \u00b6 The path to the (feather) file backing this array. create_array ( data ) classmethod \u00b6 Source code in tabular/data_types.py @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj to_pandas ( self ) \u00b6 Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_array . to_pandas () to_pylist ( self ) \u00b6 Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_array . to_pylist ()","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.KiaraTable","text":"Source code in tabular/data_types.py class KiaraTable ( KiaraModel ): @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _table_obj : pa . Table = PrivateAttr ( default = None ) def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return TABLE_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_table ( self ) -> pa . Table : if self . _table_obj is not None : return self . _table_obj if not self . data_path : raise Exception ( \"Can't retrieve table data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () self . _table_obj = table return self . _table_obj @property def column_names ( self ) -> Iterable [ str ]: return self . arrow_table . column_names @property def num_rows ( self ) -> int : return self . arrow_table . num_rows def to_pydict ( self ): return self . arrow_table . to_pydict () def to_pylist ( self ): return self . arrow_table . to_pylist () def to_pandas ( self ): return self . arrow_table . to_pandas ()","title":"KiaraTable"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.KiaraTable-attributes","text":"arrow_table : Table property readonly \u00b6 column_names : Iterable [ str ] property readonly \u00b6 data_path : str pydantic-field \u00b6 The path to the (feather) file backing this array. num_rows : int property readonly \u00b6 create_table ( data ) classmethod \u00b6 Source code in tabular/data_types.py @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj to_pandas ( self ) \u00b6 Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_table . to_pandas () to_pydict ( self ) \u00b6 Source code in tabular/data_types.py def to_pydict ( self ): return self . arrow_table . to_pydict () to_pylist ( self ) \u00b6 Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_table . to_pylist ()","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.TableType","text":"Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the Apache Arrow Table class. Source code in tabular/data_types.py class TableType ( AnyType ): \"\"\"Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the [Apache Arrow](https://arrow.apache.org) [``Table``](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html) class. \"\"\" _data_type_name = \"table\" @classmethod def python_class ( cls ) -> Type : return pa . Table def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) def _validate ( cls , value : Any ) -> None : pass if not isinstance ( value , KiaraTable ): raise Exception ( f \"invalid type ' { type ( value ) . __name__ } ', must be 'KiaraTable'.\" ) def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result","title":"TableType"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.data_types.TableType-methods","text":"parse_python_obj ( self , data ) \u00b6 Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraTable 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) python_class () classmethod \u00b6 Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return pa . Table render_as__terminal_renderable ( self , value , render_config ) \u00b6 Source code in tabular/data_types.py def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result","title":"Methods"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.models","text":"This module contains the metadata (and other) models that are used in the kiara_plugin.tabular package. Those models are convenience wrappers that make it easier for kiara to find, create, manage and version metadata -- but also other type of models -- that is attached to data, as well as kiara modules. Metadata models must be a sub-class of kiara.metadata.MetadataModel . Other models usually sub-class a pydantic BaseModel or implement custom base classes.","title":"models"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.pipelines","text":"Default (empty) module that is used as a base path for pipelines contained in this package.","title":"pipelines"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular","text":"","title":"tabular"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular-classes","text":"","title":"Classes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.CreateTableModule","text":"Source code in tabular/tabular.py class CreateTableModule ( KiaraModule ): _module_type_name = \"table.import\" _config_cls = CreateTableModuleCOnfig def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result )) def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data","title":"CreateTableModule"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.CreateTableModule-classes","text":"_config_cls ( KiaraModuleConfig ) private pydantic-model \u00b6 Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , ) Attributes \u00b6 ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type.","title":"Classes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.CreateTableModule-methods","text":"create_from__csv__file ( self , source_value ) \u00b6 Source code in tabular/tabular.py def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data create_inputs_schema ( self ) \u00b6 Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs create_outputs_schema ( self ) \u00b6 Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs process ( self , inputs , outputs ) \u00b6 Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result ))","title":"Methods"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig","text":"Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , )","title":"CreateTableModuleCOnfig"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig-attributes","text":"ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type.","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.LoadTableConfig","text":"Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , )","title":"LoadTableConfig"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.LoadTableConfig-attributes","text":"only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table.","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule","text":"Source code in tabular/tabular.py class LoadTableFromDiskModule ( KiaraModule ): _module_type_name = \"table.load_from.disk\" _config_cls = LoadTableConfig def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array )","title":"LoadTableFromDiskModule"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule-classes","text":"_config_cls ( KiaraModuleConfig ) private pydantic-model \u00b6 Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , ) Attributes \u00b6 only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table.","title":"Classes"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule-methods","text":"create_inputs_schema ( self ) \u00b6 Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs create_outputs_schema ( self ) \u00b6 Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} process ( self , inputs , outputs ) \u00b6 Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array )","title":"Methods"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.SaveTableToDiskModule","text":"Source code in tabular/tabular.py class SaveTableToDiskModule ( PersistValueModule ): _module_type_name = \"table.save_to.disk.as.feather\" def get_persistence_target_name ( self ) -> str : return \"disk\" def get_persistence_format_name ( self ) -> str : return \"arrays\" def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def _store_array ( self , array_obj : \"pa.Array\" , file_name : str , column_name : \"str\" = \"array\" ): import pyarrow as pa schema = pa . schema ([ pa . field ( column_name , array_obj . type )]) # TODO: support non-single chunk columns with pa . OSFile ( file_name , \"wb\" ) as sink : with pa . ipc . new_file ( sink , schema = schema ) as writer : batch = pa . record_batch ( array_obj . chunks , schema = schema ) writer . write ( batch )","title":"SaveTableToDiskModule"},{"location":"reference/kiara_plugin/tabular/__init__/#kiara_plugin.tabular.tabular.SaveTableToDiskModule-methods","text":"data_type__array ( self , value , persistence_config ) \u00b6 Source code in tabular/tabular.py def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure data_type__table ( self , value , persistence_config ) \u00b6 Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. Source code in tabular/tabular.py def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure get_persistence_format_name ( self ) \u00b6 Source code in tabular/tabular.py def get_persistence_format_name ( self ) -> str : return \"arrays\" get_persistence_target_name ( self ) \u00b6 Source code in tabular/tabular.py def get_persistence_target_name ( self ) -> str : return \"disk\"","title":"Methods"},{"location":"reference/kiara_plugin/tabular/data_types/","text":"This module contains the value type classes that are used in the kiara_plugin.tabular package. Classes \u00b6 ArrayType ( AnyType ) \u00b6 An array, in most cases used as a column within a table. Internally, this type uses the Apache Arrow Array to store the data in memory (and on disk). Source code in tabular/data_types.py class ArrayType ( AnyType [ KiaraArray , DataTypeConfig ]): \"\"\"An array, in most cases used as a column within a table. Internally, this type uses the [Apache Arrow](https://arrow.apache.org) [Array](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array) to store the data in memory (and on disk). \"\"\" _data_type_name = \"array\" @classmethod def python_class ( cls ) -> Type : return KiaraArray def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) def _validate ( cls , value : Any ) -> None : if not isinstance ( value , ( pa . Array , pa . ChunkedArray )): raise Exception ( f \"Invalid type ' { type ( value ) . __name__ } ', must be an Apache Arrow Array type.\" ) def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result Methods \u00b6 calculate_hash ( self , data ) \u00b6 Calculate the hash of the value. Source code in tabular/data_types.py def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) calculate_size ( self , data ) \u00b6 Source code in tabular/data_types.py def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) parse_python_obj ( self , data ) \u00b6 Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraArray 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) python_class () classmethod \u00b6 Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return KiaraArray render_as_terminal_renderable ( self , value , render_config ) \u00b6 Source code in tabular/data_types.py def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result KiaraArray ( KiaraModel ) pydantic-model \u00b6 Source code in tabular/data_types.py class KiaraArray ( KiaraModel ): # @classmethod # def create_in_temp_dir(cls, ): # # temp_f = tempfile.mkdtemp() # file_path = os.path.join(temp_f, \"array.feather\") # # def cleanup(): # shutil.rmtree(file_path, ignore_errors=True) # # atexit.register(cleanup) # # array_obj = cls(feather_path=file_path) # return array_obj @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _array_obj : pa . Array = PrivateAttr () def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return ARRAY_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_array ( self ) -> pa . Array : if self . _array_obj is not None : return self . _array_obj if not self . data_path : raise Exception ( \"Can't retrieve array data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () if len ( table . columns ) != 1 : raise Exception ( f \"Invalid serialized array data, only a single-column Table is allowed. This value is a table with { len ( table . columns ) } columns.\" ) self . _array_obj = table . column [ 0 ] return self . _array_obj def to_pylist ( self ): return self . arrow_array . to_pylist () def to_pandas ( self ): return self . arrow_array . to_pandas () Attributes \u00b6 arrow_array : Array property readonly \u00b6 data_path : str pydantic-field \u00b6 The path to the (feather) file backing this array. create_array ( data ) classmethod \u00b6 Source code in tabular/data_types.py @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj to_pandas ( self ) \u00b6 Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_array . to_pandas () to_pylist ( self ) \u00b6 Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_array . to_pylist () KiaraTable ( KiaraModel ) pydantic-model \u00b6 Source code in tabular/data_types.py class KiaraTable ( KiaraModel ): @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _table_obj : pa . Table = PrivateAttr ( default = None ) def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return TABLE_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_table ( self ) -> pa . Table : if self . _table_obj is not None : return self . _table_obj if not self . data_path : raise Exception ( \"Can't retrieve table data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () self . _table_obj = table return self . _table_obj @property def column_names ( self ) -> Iterable [ str ]: return self . arrow_table . column_names @property def num_rows ( self ) -> int : return self . arrow_table . num_rows def to_pydict ( self ): return self . arrow_table . to_pydict () def to_pylist ( self ): return self . arrow_table . to_pylist () def to_pandas ( self ): return self . arrow_table . to_pandas () Attributes \u00b6 arrow_table : Table property readonly \u00b6 column_names : Iterable [ str ] property readonly \u00b6 data_path : str pydantic-field \u00b6 The path to the (feather) file backing this array. num_rows : int property readonly \u00b6 create_table ( data ) classmethod \u00b6 Source code in tabular/data_types.py @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj to_pandas ( self ) \u00b6 Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_table . to_pandas () to_pydict ( self ) \u00b6 Source code in tabular/data_types.py def to_pydict ( self ): return self . arrow_table . to_pydict () to_pylist ( self ) \u00b6 Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_table . to_pylist () TableType ( AnyType ) \u00b6 Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the Apache Arrow Table class. Source code in tabular/data_types.py class TableType ( AnyType ): \"\"\"Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the [Apache Arrow](https://arrow.apache.org) [``Table``](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html) class. \"\"\" _data_type_name = \"table\" @classmethod def python_class ( cls ) -> Type : return pa . Table def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) def _validate ( cls , value : Any ) -> None : pass if not isinstance ( value , KiaraTable ): raise Exception ( f \"invalid type ' { type ( value ) . __name__ } ', must be 'KiaraTable'.\" ) def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result Methods \u00b6 parse_python_obj ( self , data ) \u00b6 Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraTable 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) python_class () classmethod \u00b6 Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return pa . Table render_as__terminal_renderable ( self , value , render_config ) \u00b6 Source code in tabular/data_types.py def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result","title":"data_types"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types-classes","text":"","title":"Classes"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType","text":"An array, in most cases used as a column within a table. Internally, this type uses the Apache Arrow Array to store the data in memory (and on disk). Source code in tabular/data_types.py class ArrayType ( AnyType [ KiaraArray , DataTypeConfig ]): \"\"\"An array, in most cases used as a column within a table. Internally, this type uses the [Apache Arrow](https://arrow.apache.org) [Array](https://arrow.apache.org/docs/python/generated/pyarrow.Array.html#pyarrow.Array) to store the data in memory (and on disk). \"\"\" _data_type_name = \"array\" @classmethod def python_class ( cls ) -> Type : return KiaraArray def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data )) def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data )) def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data ) def _validate ( cls , value : Any ) -> None : if not isinstance ( value , ( pa . Array , pa . ChunkedArray )): raise Exception ( f \"Invalid type ' { type ( value ) . __name__ } ', must be an Apache Arrow Array type.\" ) def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result","title":"ArrayType"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType-methods","text":"","title":"Methods"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType.calculate_hash","text":"Calculate the hash of the value. Source code in tabular/data_types.py def calculate_hash ( self , data : pa . Array ) -> int : return KIARA_HASH_FUNCTION ( memoryview ( data ))","title":"calculate_hash()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType.calculate_size","text":"Source code in tabular/data_types.py def calculate_size ( self , data : pa . Array ) -> int : return len ( memoryview ( data ))","title":"calculate_size()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType.parse_python_obj","text":"Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraArray 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraArray : return KiaraArray . create_array ( data )","title":"parse_python_obj()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType.python_class","text":"Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return KiaraArray","title":"python_class()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.ArrayType.render_as_terminal_renderable","text":"Source code in tabular/data_types.py def render_as_terminal_renderable ( self , value : Value , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" ) max_row_height = render_config . get ( \"max_row_height\" ) max_cell_length = render_config . get ( \"max_cell_length\" ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) import pyarrow as pa array : pa . Array = value . data . arrow_array temp_table = pa . Table . from_arrays ( arrays = [ array ], names = [ \"array\" ]) atw = ArrowTabularWrap ( temp_table ) result = [ atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) ] return result","title":"render_as_terminal_renderable()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray","text":"Source code in tabular/data_types.py class KiaraArray ( KiaraModel ): # @classmethod # def create_in_temp_dir(cls, ): # # temp_f = tempfile.mkdtemp() # file_path = os.path.join(temp_f, \"array.feather\") # # def cleanup(): # shutil.rmtree(file_path, ignore_errors=True) # # atexit.register(cleanup) # # array_obj = cls(feather_path=file_path) # return array_obj @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _array_obj : pa . Array = PrivateAttr () def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return ARRAY_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_array ( self ) -> pa . Array : if self . _array_obj is not None : return self . _array_obj if not self . data_path : raise Exception ( \"Can't retrieve array data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () if len ( table . columns ) != 1 : raise Exception ( f \"Invalid serialized array data, only a single-column Table is allowed. This value is a table with { len ( table . columns ) } columns.\" ) self . _array_obj = table . column [ 0 ] return self . _array_obj def to_pylist ( self ): return self . arrow_array . to_pylist () def to_pandas ( self ): return self . arrow_array . to_pandas ()","title":"KiaraArray"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray-attributes","text":"","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray.arrow_array","text":"","title":"arrow_array"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray.data_path","text":"The path to the (feather) file backing this array.","title":"data_path"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray.create_array","text":"Source code in tabular/data_types.py @classmethod def create_array ( cls , data : Any ) -> \"KiaraArray\" : array_obj = None if isinstance ( data , ( pa . Array , pa . ChunkedArray )): array_obj = data elif isinstance ( data , pa . Table ): if len ( data . columns ) != 1 : raise Exception ( f \"Invalid type, only Arrow Arrays or single-column Tables allowed. This value is a table with { len ( data . columns ) } columns.\" ) array_obj = data . column ( 0 ) else : try : array_obj = pa . array ( data ) except Exception : pass if array_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraArray () obj . _array_obj = array_obj return obj","title":"create_array()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray.to_pandas","text":"Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_array . to_pandas ()","title":"to_pandas()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraArray.to_pylist","text":"Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_array . to_pylist ()","title":"to_pylist()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable","text":"Source code in tabular/data_types.py class KiaraTable ( KiaraModel ): @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj data_path : Optional [ str ] = Field ( description = \"The path to the (feather) file backing this array.\" ) _table_obj : pa . Table = PrivateAttr ( default = None ) def _retrieve_id ( self ) -> str : return str ( uuid . uuid4 ()) def _retrieve_category_id ( self ) -> str : return TABLE_MODEL_CATEOGORY_ID def _retrieve_data_to_hash ( self ) -> Any : raise NotImplementedError () @property def arrow_table ( self ) -> pa . Table : if self . _table_obj is not None : return self . _table_obj if not self . data_path : raise Exception ( \"Can't retrieve table data, object not initialized (yet).\" ) with pa . memory_map ( self . data_path , \"r\" ) as source : table : pa . Table = pa . ipc . open_file ( source ) . read_all () self . _table_obj = table return self . _table_obj @property def column_names ( self ) -> Iterable [ str ]: return self . arrow_table . column_names @property def num_rows ( self ) -> int : return self . arrow_table . num_rows def to_pydict ( self ): return self . arrow_table . to_pydict () def to_pylist ( self ): return self . arrow_table . to_pylist () def to_pandas ( self ): return self . arrow_table . to_pandas ()","title":"KiaraTable"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable-attributes","text":"","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.arrow_table","text":"","title":"arrow_table"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.column_names","text":"","title":"column_names"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.data_path","text":"The path to the (feather) file backing this array.","title":"data_path"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.num_rows","text":"","title":"num_rows"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.create_table","text":"Source code in tabular/data_types.py @classmethod def create_table ( cls , data : Any ) -> \"KiaraTable\" : table_obj = None if isinstance ( data , KiaraTable ): return data if isinstance ( data , ( pa . Table )): table_obj = data else : try : table_obj = pa . table ( data ) except Exception : pass if table_obj is None : raise Exception ( f \"Can't create array, invalid source data type: { type ( data ) } .\" ) obj = KiaraTable () obj . _table_obj = table_obj return obj","title":"create_table()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.to_pandas","text":"Source code in tabular/data_types.py def to_pandas ( self ): return self . arrow_table . to_pandas ()","title":"to_pandas()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.to_pydict","text":"Source code in tabular/data_types.py def to_pydict ( self ): return self . arrow_table . to_pydict ()","title":"to_pydict()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.KiaraTable.to_pylist","text":"Source code in tabular/data_types.py def to_pylist ( self ): return self . arrow_table . to_pylist ()","title":"to_pylist()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.TableType","text":"Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the Apache Arrow Table class. Source code in tabular/data_types.py class TableType ( AnyType ): \"\"\"Tabular data (table, spreadsheet, data_frame, what have you). Internally, this is backed by the [Apache Arrow](https://arrow.apache.org) [``Table``](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html) class. \"\"\" _data_type_name = \"table\" @classmethod def python_class ( cls ) -> Type : return pa . Table def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data ) def _validate ( cls , value : Any ) -> None : pass if not isinstance ( value , KiaraTable ): raise Exception ( f \"invalid type ' { type ( value ) . __name__ } ', must be 'KiaraTable'.\" ) def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result","title":"TableType"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.TableType-methods","text":"","title":"Methods"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.TableType.parse_python_obj","text":"Parse a value into a supported python type. This exists to make it easier to do trivial conversions (e.g. from a date string to a datetime object). If you choose to overwrite this method, make 100% sure that you don't change the meaning of the value, and try to avoid adding or removing information from the data (e.g. by changing the resolution of a date). Parameters: Name Type Description Default v the value required Returns: Type Description KiaraTable 'None', if no parsing was done and the original value should be used, otherwise return the parsed Python object Source code in tabular/data_types.py def parse_python_obj ( self , data : Any ) -> KiaraTable : return KiaraTable . create_table ( data )","title":"parse_python_obj()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.TableType.python_class","text":"Source code in tabular/data_types.py @classmethod def python_class ( cls ) -> Type : return pa . Table","title":"python_class()"},{"location":"reference/kiara_plugin/tabular/data_types/#kiara_plugin.tabular.data_types.TableType.render_as__terminal_renderable","text":"Source code in tabular/data_types.py def render_as__terminal_renderable ( self , value : \"Value\" , render_config : Mapping [ str , Any ] ) -> Any : max_rows = render_config . get ( \"max_no_rows\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_no_rows\" ] ) max_row_height = render_config . get ( \"max_row_height\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_row_height\" ] ) max_cell_length = render_config . get ( \"max_cell_length\" , DEFAULT_PRETTY_PRINT_CONFIG [ \"max_cell_length\" ] ) half_lines : Optional [ int ] = None if max_rows : half_lines = int ( max_rows / 2 ) atw = ArrowTabularWrap ( value . data . arrow_table ) result = atw . pretty_print ( rows_head = half_lines , rows_tail = half_lines , max_row_height = max_row_height , max_cell_length = max_cell_length , ) return result","title":"render_as__terminal_renderable()"},{"location":"reference/kiara_plugin/tabular/models/","text":"This module contains the metadata (and other) models that are used in the kiara_plugin.tabular package. Those models are convenience wrappers that make it easier for kiara to find, create, manage and version metadata -- but also other type of models -- that is attached to data, as well as kiara modules. Metadata models must be a sub-class of kiara.metadata.MetadataModel . Other models usually sub-class a pydantic BaseModel or implement custom base classes.","title":"models"},{"location":"reference/kiara_plugin/tabular/tabular/","text":"Classes \u00b6 CreateTableModule ( KiaraModule ) \u00b6 Source code in tabular/tabular.py class CreateTableModule ( KiaraModule ): _module_type_name = \"table.import\" _config_cls = CreateTableModuleCOnfig def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result )) def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data Classes \u00b6 _config_cls ( KiaraModuleConfig ) private pydantic-model \u00b6 Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , ) Attributes \u00b6 ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type. Methods \u00b6 create_from__csv__file ( self , source_value ) \u00b6 Source code in tabular/tabular.py def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data create_inputs_schema ( self ) \u00b6 Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs create_outputs_schema ( self ) \u00b6 Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs process ( self , inputs , outputs ) \u00b6 Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result )) CreateTableModuleCOnfig ( KiaraModuleConfig ) pydantic-model \u00b6 Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , ) Attributes \u00b6 ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type. LoadTableConfig ( KiaraModuleConfig ) pydantic-model \u00b6 Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , ) Attributes \u00b6 only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table. LoadTableFromDiskModule ( KiaraModule ) \u00b6 Source code in tabular/tabular.py class LoadTableFromDiskModule ( KiaraModule ): _module_type_name = \"table.load_from.disk\" _config_cls = LoadTableConfig def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array ) Classes \u00b6 _config_cls ( KiaraModuleConfig ) private pydantic-model \u00b6 Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , ) Attributes \u00b6 only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table. Methods \u00b6 create_inputs_schema ( self ) \u00b6 Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs create_outputs_schema ( self ) \u00b6 Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} process ( self , inputs , outputs ) \u00b6 Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array ) SaveTableToDiskModule ( PersistValueModule ) \u00b6 Source code in tabular/tabular.py class SaveTableToDiskModule ( PersistValueModule ): _module_type_name = \"table.save_to.disk.as.feather\" def get_persistence_target_name ( self ) -> str : return \"disk\" def get_persistence_format_name ( self ) -> str : return \"arrays\" def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def _store_array ( self , array_obj : \"pa.Array\" , file_name : str , column_name : \"str\" = \"array\" ): import pyarrow as pa schema = pa . schema ([ pa . field ( column_name , array_obj . type )]) # TODO: support non-single chunk columns with pa . OSFile ( file_name , \"wb\" ) as sink : with pa . ipc . new_file ( sink , schema = schema ) as writer : batch = pa . record_batch ( array_obj . chunks , schema = schema ) writer . write ( batch ) Methods \u00b6 data_type__array ( self , value , persistence_config ) \u00b6 Source code in tabular/tabular.py def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure data_type__table ( self , value , persistence_config ) \u00b6 Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. Source code in tabular/tabular.py def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure get_persistence_format_name ( self ) \u00b6 Source code in tabular/tabular.py def get_persistence_format_name ( self ) -> str : return \"arrays\" get_persistence_target_name ( self ) \u00b6 Source code in tabular/tabular.py def get_persistence_target_name ( self ) -> str : return \"disk\"","title":"tabular"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular-classes","text":"","title":"Classes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule","text":"Source code in tabular/tabular.py class CreateTableModule ( KiaraModule ): _module_type_name = \"table.import\" _config_cls = CreateTableModuleCOnfig def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result )) def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data","title":"CreateTableModule"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule-classes","text":"","title":"Classes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule._config_cls","text":"Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , )","title":"_config_cls"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule._config_cls-attributes","text":"ignore_errors : bool pydantic-field \u00b6 Whether to ignore convert errors and omit the failed items. source_profile : str pydantic-field required \u00b6 The source profile name. source_type : str pydantic-field required \u00b6 The source data type.","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule-methods","text":"","title":"Methods"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule.create_from__csv__file","text":"Source code in tabular/tabular.py def create_from__csv__file ( self , source_value : Value ) -> Any : from pyarrow import csv input_file : FileModel = source_value . data imported_data = csv . read_csv ( input_file . path ) return imported_data","title":"create_from__csv__file()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule.create_inputs_schema","text":"Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : source_type = self . get_config_value ( \"source_type\" ) inputs = { source_type : { \"type\" : source_type , \"doc\" : \"The source data.\" }} return inputs","title":"create_inputs_schema()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule.create_outputs_schema","text":"Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : outputs = { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The (new) table.\" , } } return outputs","title":"create_outputs_schema()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModule.process","text":"Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ) -> None : source_type = self . get_config_value ( \"source_type\" ) source_profile_name = self . get_config_value ( \"source_profile\" ) func_name = f \"create_from__ { source_profile_name } __ { source_type } \" func = getattr ( self , func_name ) source_value = inputs . get_value_obj ( source_type ) result = func ( source_value = source_value ) outputs . set_value ( \"table\" , KiaraTable . create_table ( result ))","title":"process()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig","text":"Source code in tabular/tabular.py class CreateTableModuleCOnfig ( KiaraModuleConfig ): source_profile : str = Field ( description = \"The source profile name.\" ) source_type : str = Field ( description = \"The source data type.\" ) ignore_errors : bool = Field ( description = \"Whether to ignore convert errors and omit the failed items.\" , default = False , )","title":"CreateTableModuleCOnfig"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig-attributes","text":"","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig.ignore_errors","text":"Whether to ignore convert errors and omit the failed items.","title":"ignore_errors"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig.source_profile","text":"The source profile name.","title":"source_profile"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.CreateTableModuleCOnfig.source_type","text":"The source data type.","title":"source_type"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableConfig","text":"Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , )","title":"LoadTableConfig"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableConfig-attributes","text":"","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableConfig.only_column","text":"Whether to only load a single column instead of the whole table.","title":"only_column"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule","text":"Source code in tabular/tabular.py class LoadTableFromDiskModule ( KiaraModule ): _module_type_name = \"table.load_from.disk\" _config_cls = LoadTableConfig def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }} def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array )","title":"LoadTableFromDiskModule"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule-classes","text":"","title":"Classes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule._config_cls","text":"Source code in tabular/tabular.py class LoadTableConfig ( KiaraModuleConfig ): only_column : Optional [ str ] = Field ( description = \"Whether to only load a single column instead of the whole table.\" , default = None , )","title":"_config_cls"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule._config_cls-attributes","text":"only_column : str pydantic-field \u00b6 Whether to only load a single column instead of the whole table.","title":"Attributes"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule-methods","text":"","title":"Methods"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule.create_inputs_schema","text":"Return the schema for this types' inputs. Source code in tabular/tabular.py def create_inputs_schema ( self , ) -> ValueSetSchema : inputs = { \"bytes_structure\" : { \"type\" : \"any\" , \"doc\" : \"The bytes.\" }} return inputs","title":"create_inputs_schema()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule.create_outputs_schema","text":"Return the schema for this types' outputs. Source code in tabular/tabular.py def create_outputs_schema ( self , ) -> ValueSetSchema : if not self . get_config_value ( \"only_column\" ): return { \"table\" : { \"type\" : \"table\" , \"doc\" : \"The table.\" }} else : return { \"array\" : { \"type\" : \"array\" , \"doc\" : \"The array.\" }}","title":"create_outputs_schema()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.LoadTableFromDiskModule.process","text":"Source code in tabular/tabular.py def process ( self , inputs : ValueSet , outputs : ValueSet ): import pyarrow as pa bytes_structure : BytesStructure = inputs . get_value_data ( \"bytes_structure\" ) if not self . get_config_value ( \"only_column\" ): columns = {} for column_name , chunks in bytes_structure . chunk_map . items (): assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays : pa . Table = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( column_name ) columns [ column_name ] = column arrow_table = pa . table ( columns ) table = KiaraTable . create_table ( arrow_table ) outputs . set_value ( \"table\" , table ) else : chunks = bytes_structure . chunk_map [ \"array.arrow\" ] assert len ( chunks ) == 1 with pa . memory_map ( chunks [ 0 ], \"r\" ) as column_chunk : loaded_arrays = pa . ipc . open_file ( column_chunk ) . read_all () column = loaded_arrays . column ( \"array\" ) array = KiaraArray . create_array ( column ) outputs . set_value ( \"array\" , array )","title":"process()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.SaveTableToDiskModule","text":"Source code in tabular/tabular.py class SaveTableToDiskModule ( PersistValueModule ): _module_type_name = \"table.save_to.disk.as.feather\" def get_persistence_target_name ( self ) -> str : return \"disk\" def get_persistence_format_name ( self ) -> str : return \"arrays\" def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure def _store_array ( self , array_obj : \"pa.Array\" , file_name : str , column_name : \"str\" = \"array\" ): import pyarrow as pa schema = pa . schema ([ pa . field ( column_name , array_obj . type )]) # TODO: support non-single chunk columns with pa . OSFile ( file_name , \"wb\" ) as sink : with pa . ipc . new_file ( sink , schema = schema ) as writer : batch = pa . record_batch ( array_obj . chunks , schema = schema ) writer . write ( batch )","title":"SaveTableToDiskModule"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.SaveTableToDiskModule-methods","text":"","title":"Methods"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.SaveTableToDiskModule.data_type__array","text":"Source code in tabular/tabular.py def data_type__array ( self , value : Value , persistence_config : Mapping [ str , Any ]): import pyarrow as pa kiara_array : KiaraArray = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) column : pa . Array = kiara_array . arrow_array file_name = os . path . join ( temp_f , \"array.arrow\" ) self . _store_array ( array_obj = column , file_name = file_name , column_name = \"array\" ) chunk_map [ \"array.arrow\" ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"array.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure","title":"data_type__array()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.SaveTableToDiskModule.data_type__table","text":"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. Source code in tabular/tabular.py def data_type__table ( self , value : Value , persistence_config : Mapping [ str , Any ] ) -> Tuple [ LoadConfig , Optional [ BytesStructure ]]: \"\"\"Store the table as Apache Arrow feather file The table will be store with one feather file per column, to support de-duplicated storage of re-arranged tables. \"\"\" import pyarrow as pa table : KiaraTable = value . data chunk_map = {} # TODO: make sure temp dir is in the same partition as file store temp_f = tempfile . mkdtemp () def cleanup (): shutil . rmtree ( temp_f , ignore_errors = True ) atexit . register ( cleanup ) for column_name in table . arrow_table . column_names : column : pa . Array = table . arrow_table . column ( column_name ) file_name = os . path . join ( temp_f , column_name ) self . _store_array ( array_obj = column , file_name = file_name , column_name = column_name ) chunk_map [ column_name ] = [ file_name ] bytes_structure_data : Dict [ str , Any ] = { \"data_type\" : value . value_schema . type , \"data_type_config\" : value . value_schema . type_config , \"chunk_map\" : chunk_map , } bytes_structure = BytesStructure . construct ( ** bytes_structure_data ) load_config_data = { \"provisioning_strategy\" : ByteProvisioningStrategy . FILE_PATH_MAP , \"module_type\" : \"table.load_from.disk\" , \"inputs\" : { \"bytes_structure\" : \"__dummy__\" }, \"output_name\" : value . value_schema . type , } load_config = LoadConfig ( ** load_config_data ) return load_config , bytes_structure","title":"data_type__table()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.SaveTableToDiskModule.get_persistence_format_name","text":"Source code in tabular/tabular.py def get_persistence_format_name ( self ) -> str : return \"arrays\"","title":"get_persistence_format_name()"},{"location":"reference/kiara_plugin/tabular/tabular/#kiara_plugin.tabular.tabular.SaveTableToDiskModule.get_persistence_target_name","text":"Source code in tabular/tabular.py def get_persistence_target_name ( self ) -> str : return \"disk\"","title":"get_persistence_target_name()"},{"location":"reference/kiara_plugin/tabular/pipelines/__init__/","text":"Default (empty) module that is used as a base path for pipelines contained in this package.","title":"pipelines"}]}